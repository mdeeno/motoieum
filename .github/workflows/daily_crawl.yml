name: Auto Crawler

on:
  schedule:
    # 1ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰ (ë§¤ì‹œ ì •ê°)
    - cron: '0 * * * *'
  workflow_dispatch: # ìˆ˜ë™ ì‹¤í–‰ ë²„íŠ¼

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ“¥ ì €ì¥ì†Œ ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
        uses: actions/checkout@v3

      - name: ğŸ íŒŒì´ì¬ ì„¤ì •í•˜ê¸°
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
        run: |
          pip install -r requirements.txt

      - name: ğŸ¤– ì¤‘ê²€ë‹¨ ë¡œë´‡ ì¶œë™ (joongum_bot.py)
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python scrapers/joongum_bot.py

      - name: ğŸï¸ ë°”íŠœë§¤ ë¡œë´‡ ì¶œë™ (auto_batumae.py)
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python scrapers/auto_batumae.py
