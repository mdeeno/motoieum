name: Auto Crawler

on:
  schedule:
    # 2ì‹œê°„ë§ˆë‹¤ ì‹¤í–‰ (UTC ê¸°ì¤€ ì§ìˆ˜ ì‹œê°„)
    - cron: '0 */2 * * *'
  workflow_dispatch: # ê¹ƒí—ˆë¸Œ í™ˆí˜ì´ì§€ì—ì„œ ë²„íŠ¼ ëˆŒëŸ¬ì„œ ìˆ˜ë™ ì‹¤í–‰ ê°€ëŠ¥

jobs:
  build:
    runs-on: ubuntu-latest

    steps:
      - name: ğŸ“¥ ì €ì¥ì†Œ ì½”ë“œ ê°€ì ¸ì˜¤ê¸°
        uses: actions/checkout@v3

      - name: ğŸ íŒŒì´ì¬ ì„¤ì •í•˜ê¸°
        uses: actions/setup-python@v4
        with:
          python-version: '3.9'

      - name: ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
        run: |
          pip install -r requirements.txt

      - name: ğŸ¤– ì¤‘ê²€ë‹¨ ë¡œë´‡ ì¶œë™ (joongum_bot.py)
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python scrapers/joongum_bot.py

      - name: ğŸï¸ ë°”íŠœë§¤ ë¡œë´‡ ì¶œë™ (auto_batumae.py)
        env:
          SUPABASE_URL: ${{ secrets.SUPABASE_URL }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_KEY }}
        run: python scrapers/auto_batumae.py
