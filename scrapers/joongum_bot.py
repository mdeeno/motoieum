import os
import time
import re
from pathlib import Path
from dotenv import load_dotenv
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.options import Options
from webdriver_manager.chrome import ChromeDriverManager
from supabase import create_client, Client

# --- 1. ì„¤ì • ë° ê²½ë¡œ ---
BASE_DIR = Path(__file__).resolve().parent.parent 
ENV_PATH = os.path.join(BASE_DIR, ".env")

if os.path.exists(ENV_PATH):
    load_dotenv(ENV_PATH)

url = os.getenv("SUPABASE_URL")
key = os.getenv("SUPABASE_KEY")

if not url or not key:
    raise ValueError("âŒ .env íŒŒì¼ ì„¤ì •ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")

supabase: Client = create_client(url, key)

# --- 2. ë°ì´í„° ì •ì œ í•¨ìˆ˜ ---
def clean_price(text):
    if not text: return "ê°€ê²© ë¬¸ì˜"
    text = text.replace(',', '').strip()
    # '8600000ì›' -> '8600000'
    nums = re.findall(r'\d+', text)
    if nums: return nums[0]
    return "ê°€ê²© ë¬¸ì˜"

def clean_mileage(text):
    if not text: return "0"
    nums = re.findall(r'\d+', text.replace(',', ''))
    if nums: return f"{int(nums[0]):,}"
    return "0"

def get_text_by_label(driver, label_list):
    """ ìƒì„¸í˜ì´ì§€ ìŠ¤í™í‘œì—ì„œ ê°’ ì¶”ì¶œ """
    for label in label_list:
        try:
            xpath = f"//*[contains(text(), '{label}')]"
            elements = driver.find_elements(By.XPATH, xpath)
            for el in elements:
                try:
                    # Case 1: td + td êµ¬ì¡°
                    val = el.find_element(By.XPATH, "./following-sibling::*[1]").text.strip()
                    if val: return val
                except: pass
                try:
                    # Case 2: div êµ¬ì¡°
                    val = el.find_element(By.XPATH, "../following-sibling::*[1]").text.strip()
                    if val: return val
                except: pass
        except: continue
    return None

def fix_image_url(src):
    """ 
    ë¬¸ì œì˜ '/../upload/...' ê²½ë¡œë¥¼ ì •ìƒì ì¸ URLë¡œ ë³€í™˜ 
    """
    if not src: return "http://joongum.co.kr/img/common/no_image.gif"
    
    # 1. ì´ìƒí•œ ìƒëŒ€ê²½ë¡œ ì¹˜í™˜ (/../ -> /)
    if "/../" in src:
        src = src.replace("/../", "/")
    
    # 2. ë„ë©”ì¸ì´ ì—†ìœ¼ë©´ ë¶™ì—¬ì¤Œ
    if src.startswith("/"):
        return f"http://joongum.co.kr{src}"
    
    return src

# --- 3. ë©”ì¸ í¬ë¡¤ëŸ¬ ---
def run_joongum_crawler():
    print("ğŸ¤– [ê°€ë™] ì¤‘ê²€ë‹¨ ë¡œë´‡ (ì´ë¯¸ì§€/ì œëª© ë³µêµ¬ ë²„ì „)")
    
    options = Options()
    options.add_argument("--headless")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--disable-popup-blocking")
    
    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)
    
    try:
        # 1. ëª©ë¡ í˜ì´ì§€ ì ‘ì†
        target_url = "http://joongum.co.kr/search_list"
        print(f"ğŸ”— ì ‘ì† ì¤‘: {target_url}")
        driver.get(target_url)
        time.sleep(2)
        
        # 2. ì¹´ë“œ(div.area) ë‹¨ìœ„ë¡œ ìš”ì†Œ ì°¾ê¸°
        cards = driver.find_elements(By.CSS_SELECTOR, "div.list-in div.area")
        print(f"ğŸ“„ ëª©ë¡ì—ì„œ {len(cards)}ê°œì˜ ë§¤ë¬¼ì„ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
        
        crawling_targets = []

        # 3. ëª©ë¡ì—ì„œ 1ì°¨ ì •ë³´(ë§í¬, ì œëª©, ì´ë¯¸ì§€) ìˆ˜ì§‘
        for card in cards:
            try:
                # A. ë§í¬ ì¶”ì¶œ (onclick ë¶„ì„)
                onclick_text = card.get_attribute("onclick")
                link = None
                if onclick_text and "search_view" in onclick_text:
                    match = re.search(r"search_view/\d+", onclick_text)
                    if match:
                        link = f"http://joongum.co.kr/{match.group(0)}"
                
                if not link: continue

                # B. ì œëª© ì¶”ì¶œ (ëª©ë¡ì— ìˆëŠ” ì •ë³´ê°€ ë” ì •í™•í•¨)
                # HTML ì˜ˆì‹œ: <div class="product_tit"> <span class="company">ì•¼ë§ˆí•˜</span> <span class="model">R3</span></div>
                try:
                    title_element = card.find_element(By.CSS_SELECTOR, ".product_tit")
                    title = title_element.text.strip().replace("\n", " ") # ì•¼ë§ˆí•˜ R3
                except:
                    title = "ì œëª© ì—†ìŒ"

                # C. ì´ë¯¸ì§€ ì¶”ì¶œ ë° ìˆ˜ë¦¬
                img_src = None
                try:
                    img_el = card.find_element(By.CSS_SELECTOR, ".thumnail img")
                    raw_src = img_el.get_attribute("src")
                    img_src = fix_image_url(raw_src) # ğŸ› ï¸ ì—¬ê¸°ì„œ ì´ë¯¸ì§€ ì£¼ì†Œ ê³ ì¹¨
                except:
                    img_src = "http://joongum.co.kr/img/common/no_image.gif"

                # ìˆ˜ì§‘ ëŒ€ìƒì— ì¶”ê°€
                crawling_targets.append({
                    "link": link,
                    "title": title,
                    "img_src": img_src
                })

            except Exception:
                continue

        # 4. ìƒì„¸ í˜ì´ì§€ ìˆœíšŒí•˜ë©° ë‚˜ë¨¸ì§€ ì •ë³´(ì—°ì‹, ì£¼í–‰ê±°ë¦¬, ê°€ê²©) ì±„ìš°ê¸°
        collected_count = 0
        
        # ìµœì‹  15ê°œë§Œ ì§„í–‰
        for i, target in enumerate(crawling_targets[:15]):
            try:
                print(f"   [{i+1}/{len(crawling_targets[:15])}] ë¶„ì„ ì¤‘: {target['title']}...", end="\r")
                
                driver.get(target['link'])
                time.sleep(0.8) # ë¡œë”© ëŒ€ê¸°

                # ìƒì„¸ ë°ì´í„° ì¶”ì¶œ
                raw_price = get_text_by_label(driver, ["íŒë§¤ê°€", "íŒë§¤ê¸ˆì•¡", "ê°€ê²©"])
                raw_year = get_text_by_label(driver, ["ì—°ì‹", "ë…„ì‹"])
                raw_mileage = get_text_by_label(driver, ["ì£¼í–‰ê±°ë¦¬", "ì ì‚°ê±°ë¦¬", "í‚¤ë¡œìˆ˜"])
                
                # ë°ì´í„° ì •ì œ
                price = clean_price(raw_price)
                year = raw_year if raw_year else "ì—°ì‹ ë¯¸ìƒ"
                mileage = clean_mileage(raw_mileage)
                
                # ìµœì¢… ë°ì´í„° íŒ¨í‚¤ì§•
                data = {
                    "title": target['title'],  # ëª©ë¡ì—ì„œ ê°€ì ¸ì˜¨ ê¹”ë”í•œ ì œëª©
                    "price": price,
                    "location": "ì „êµ­(íƒì†¡ê°€ëŠ¥)",
                    "image_url": target['img_src'], # ìˆ˜ë¦¬ëœ ì´ë¯¸ì§€ ì£¼ì†Œ
                    "source": "joongum", # ì¶œì²˜ ëª…ì‹œ
                    "external_link": target['link'],
                    "year": year,
                    "mileage": mileage,
                    "content": f"#ì¤‘ê²€ë‹¨ì¸ì¦ \nì „ë¬¸ê°€ ì ê²€ ë§¤ë¬¼ì…ë‹ˆë‹¤. ìƒì„¸ë¦¬í¬íŠ¸: {target['link']}",
                    "status": "íŒë§¤ì¤‘"
                }
                
                # DB ì €ì¥ (Upsert)
                existing = supabase.table('market').select('id').eq('external_link', target['link']).execute()
                if not existing.data:
                    supabase.table('market').insert(data).execute()
                    collected_count += 1
                else:
                    supabase.table('market').update({
                        "price": price,
                        "title": target['title'], # ì œëª© ì—…ë°ì´íŠ¸
                        "image_url": target['img_src'], # ì´ë¯¸ì§€ ì—…ë°ì´íŠ¸
                        "source": "joongum",
                        "status": "íŒë§¤ì¤‘"
                    }).eq('external_link', target['link']).execute()

            except Exception as e:
                # print(f"   âš ï¸ ìƒì„¸ ì—ëŸ¬: {e}")
                continue
                
        print(f"\nğŸ‰ ì™„ë£Œ! {collected_count}ê°œì˜ ì¤‘ê²€ë‹¨ ë§¤ë¬¼ì„ ì €ì¥/ê°±ì‹ í–ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"ğŸ’¥ ì—ëŸ¬: {e}")
    finally:
        driver.quit()

if __name__ == "__main__":
    run_joongum_crawler()