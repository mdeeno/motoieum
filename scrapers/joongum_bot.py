import requests
from bs4 import BeautifulSoup
from supabase import create_client
import os
import re

# 1. í™˜ê²½ë³€ìˆ˜ ì„¤ì •
SUPABASE_URL = os.environ.get("SUPABASE_URL")
SUPABASE_KEY = os.environ.get("SUPABASE_KEY")

if not SUPABASE_URL or not SUPABASE_KEY:
    print("âŒ í™˜ê²½ë³€ìˆ˜(SUPABASE_URL, SUPABASE_KEY)ê°€ ì—†ìŠµë‹ˆë‹¤.")
    exit(1)

supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

def parse_price(price_text):
    if not price_text:
        return "ê°€ê²©ë¬¸ì˜"
    clean = re.sub(r'[^\d]', '', price_text)
    if not clean:
        return "ê°€ê²©ë¬¸ì˜"
    return clean

def run_joongum_crawler():
    print("ğŸ¤– [ê°€ë™] ì¤‘ê²€ë‹¨ ë¡œë´‡ (Requests ë°©ì‹)")
    url = "http://joongum.co.kr/search_list"
    headers = {
        "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
    }

    try:
        res = requests.get(url, headers=headers)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        
        items = soup.select('.products_list > li') or soup.select('.list_box > li')
        if not items:
            print("âŒ ëª©ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        print(f"   -> ë§¤ë¬¼ {len(items)}ê°œ ë°œê²¬! ë¶„ì„ ì‹œì‘...")
        count = 0
        for item in items[:15]:
            try:
                link_tag = item.select_one('a')
                if not link_tag: continue
                href = link_tag.get('href')
                link = f"http://joongum.co.kr{href}" if not href.startswith('http') else href
                
                title_tag = item.select_one('.title') or item.select_one('.subject')
                if not title_tag: continue
                title = title_tag.get_text(strip=True)

                price_tag = item.select_one('.price')
                price = parse_price(price_tag.get_text(strip=True) if price_tag else "0")

                img_tag = item.select_one('img')
                img_src = img_tag.get('src') if img_tag else None
                if img_src and not img_src.startswith('http'):
                    img_src = f"http://joongum.co.kr{img_src}"

                existing = supabase.table("market").select("id").eq("external_link", link).execute()
                if existing.data:
                    print(f"      [Pass] ì¤‘ë³µ: {title}")
                    continue

                data = {
                    "title": f"[ì¤‘ê²€ë‹¨] {title}",
                    "content": "ì¤‘ê²€ë‹¨ ë§¤ë¬¼ì…ë‹ˆë‹¤. ìƒì„¸ ë‚´ìš©ì€ ë§í¬ë¥¼ í™•ì¸í•˜ì„¸ìš”.", 
                    "price": price,
                    "image_url": img_src,
                    "external_link": link,
                    "source": "joongum",
                    "year": "2024",
                    "mileage": "0km"
                }
                supabase.table("market").insert(data).execute()
                print(f"      âœ… [ì €ì¥] {title}")
                count += 1
            except Exception as e:
                print(f"      âš ï¸ í•­ëª© ì—ëŸ¬: {e}")
        print(f"\nğŸ‰ ì´ {count}ê°œ ì €ì¥ ì™„ë£Œ.")
    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì „ì²´ ì—ëŸ¬: {e}")

if __name__ == "__main__":
    run_joongum_crawler()